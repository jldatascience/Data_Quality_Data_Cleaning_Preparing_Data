{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codage des caractères\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points traités dans ce notebook :\n",
    "\n",
    "- Mettre en place notre environnement\n",
    "- Que sont les encodages ?\n",
    "- Lire des fichiers avec des problèmes d'encodage\n",
    "- Sauvegarder vos fichiers avec l'encodage UTF-8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place de notre environnement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première chose à faire est de charger les bibliothèques que nous utiliserons. Mais pas nos jeux de données : nous y reviendrons plus tard !\n",
    "\n",
    "Important ! Assurez-vous d'exécuter cette cellule vous-même ou le reste de votre code ne fonctionnera pas !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# librairie d'encodage de caractères utile\n",
    "import chardet\n",
    "\n",
    "# reproductibilité\n",
    "np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qu'est-ce qu'un encodage ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les codages de caractères sont des ensembles de règles spécifiques permettant de passer de chaînes d'octets binaires brutes (qui ressemblent à ceci : 0110100001101001) aux caractères qui composent un texte lisible par l'homme (comme \"hi\"). Il existe de nombreux codages différents, et si vous essayez de lire un texte avec un codage différent de celui dans lequel il a été écrit à l'origine, vous obtenez un texte brouillé appelé \"mojibake\" (qui se prononce comme mo-gee-bah-kay). Voici un exemple de mojibake :\n",
    "\n",
    "æ-‡å-åŒ-ã ??\n",
    "\n",
    "Vous pouvez également vous retrouver avec des caractères \"inconnus\". C'est ce qui s'affiche lorsqu'il n'y a pas de correspondance entre un octet particulier et un caractère dans l'encodage que vous utilisez pour lire votre chaîne d'octets et qui ressemble à ceci :\n",
    "\n",
    "����������\n",
    "\n",
    "Les erreurs d'encodage de caractères sont moins fréquentes aujourd'hui qu'elles ne l'étaient auparavant, mais elles constituent toujours un problème. Il existe de nombreux codages de caractères différents, mais le principal que vous devez connaître est UTF-8.\n",
    "\n",
    "UTF-8 est l'encodage de texte standard. Tout le code Python est en UTF-8 et, idéalement, toutes vos données devraient l'être aussi. C'est lorsque les choses ne sont pas en UTF-8 que vous rencontrez des problèmes.\n",
    "\n",
    "Il était assez difficile de gérer les encodages dans Python 2, mais heureusement, dans Python 3, c'est beaucoup plus simple. (Les Kaggle Kernels n'utilisent que Python 3.) Il y a deux types de données principaux que vous rencontrerez lorsque vous travaillerez avec du texte en Python 3. Le premier est la chaîne de caractères, qui est le type de texte par défaut."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes maintenant prêts à travailler avec des encodages de caractères ! (Si vous le souhaitez, vous pouvez ajouter une cellule de code ici et profiter de l'occasion pour jeter un coup d'œil à certaines données)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# commencer par une chaîne de caractères\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# vérifie quel est le type de données\n",
    "type(before)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'autre donnée est le type de données bytes, qui est une séquence d'entiers. Vous pouvez convertir une chaîne de caractères en octets en spécifiant l'encodage utilisé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  l'encoder dans un encodage différent, en remplaçant les caractères qui soulèvent des erreurs\n",
    "after = before.encode(\"utf-8\", errors = \"replace\")\n",
    "\n",
    "# vérifier le type\n",
    "type(after)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous regardez un objet octet, vous verrez qu'il est précédé d'un b et qu'il est suivi d'un peu de texte. C'est parce que les octets sont imprimés comme s'ils étaient des caractères codés en ASCII. (L'ASCII est un ancien codage de caractères qui ne fonctionne pas vraiment pour l'écriture d'une langue autre que l'anglais). Ici, vous pouvez voir que notre symbole de l'euro a été remplacé par un mojibake qui ressemble à \"\\xe2\\x82\\xac\" lorsqu'il est imprimé comme s'il s'agissait d'une chaîne ASCII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'This is the euro symbol: \\xe2\\x82\\xac'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voir à quoi ressemblent les octets\n",
    "after"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque nous reconvertissons nos octets en une chaîne de caractères avec le bon encodage, nous pouvons voir que notre texte est bien présent, ce qui est très bien !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: €\n"
     ]
    }
   ],
   "source": [
    "# le reconvertir en utf-8\n",
    "print(after.decode(\"utf-8\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, lorsque nous essayons d'utiliser un encodage différent pour convertir nos octets en une chaîne de caractères, nous obtenons une erreur. C'est parce que l'encodage que nous essayons d'utiliser ne sait pas quoi faire avec les octets que nous essayons de lui passer. Vous devez indiquer à Python l'encodage dans lequel la chaîne d'octets est censée être.\n",
    "\n",
    "On peut comparer les différents encodages à différentes manières d'enregistrer de la musique. Vous pouvez enregistrer la même musique sur un CD, une cassette ou un 8 pistes. Bien que la musique ait plus ou moins le même son, vous devez utiliser l'équipement approprié pour lire la musique de chaque format d'enregistrement. Le décodeur approprié est comme un lecteur de cassettes ou un lecteur de CD. Si vous essayez de lire une cassette dans un lecteur de CD, cela ne fonctionnera pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# essayer de décoder nos octets avec l'encodage ascii\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(after\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mascii\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# essayer de décoder nos octets avec l'encodage ascii\n",
    "print(after.decode(\"ascii\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons également rencontrer des problèmes si nous essayons d'utiliser le mauvais encodage pour passer d'une chaîne à des octets. Comme je l'ai dit plus haut, les chaînes sont UTF-8 par défaut dans Python 3, donc si nous essayons de les traiter comme si elles étaient dans un autre encodage, nous allons créer des problèmes.\n",
    "\n",
    "Par exemple, si nous essayons de convertir une chaîne en octets pour l'ascii en utilisant encode(), nous pouvons demander que les octets soient ce qu'ils seraient si le texte était en ASCII. Mais comme notre texte n'est pas en ASCII, il y aura des caractères qu'il ne pourra pas gérer. Nous pouvons remplacer automatiquement les caractères que l'ASCII ne peut pas gérer. Si nous faisons cela, cependant, tous les caractères qui ne sont pas en ASCII seront simplement remplacés par le caractère inconnu. Ensuite, lorsque nous reconvertissons les octets en chaîne de caractères, le caractère sera remplacé par le caractère inconnu. Ce qui est dangereux, c'est qu'il n'y a aucun moyen de savoir quel caractère aurait dû être remplacé. Cela signifie que nous venons peut-être de rendre nos données inutilisables !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: ?\n"
     ]
    }
   ],
   "source": [
    "# commencer par une chaîne de caractères\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# l'encoder dans un encodage différent, en remplaçant les caractères qui soulèvent des erreurs\n",
    "after = before.encode(\"ascii\", errors = \"replace\")\n",
    "\n",
    "# le reconvertir en utf-8\n",
    "print(after.decode(\"ascii\"))\n",
    "\n",
    "# Nous avons perdu la chaîne d'octets sous-jacente d'origine ! Elle a été \n",
    "# remplacée par la chaîne d'octets sous-jacente du caractère inconnu :("
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est une mauvaise chose et nous voulons l'éviter ! Il est de loin préférable de convertir tout notre texte en UTF-8 dès que possible et de le conserver dans cet encodage. Le meilleur moment pour convertir des données non UTF-8 en UTF-8 est lorsque vous lisez des fichiers, ce dont nous parlerons plus loin.\n",
    "\n",
    "Cependant, essayez d'abord de convertir des octets et des chaînes de caractères avec des encodages différents et voyez ce qui se passe. Remarquez l'effet que cela a sur votre texte. Aimeriez-vous que cela se produise avec des données que vous essayez d'analyser ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture de fichiers présentant des problèmes d'encodag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des fichiers que vous rencontrerez seront probablement encodés en UTF-8. C'est ce que Python attend par défaut, donc la plupart du temps vous ne rencontrerez pas de problèmes. Cependant, vous obtiendrez parfois une erreur comme celle-ci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x99 in position 7955: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# essayer de lire un fichier qui n'est pas en UTF-8\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m kickstarter_2016 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/jl/Downloads/ks-projects-201612.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x99 in position 7955: invalid start byte"
     ]
    }
   ],
   "source": [
    "# essayer de lire un fichier qui n'est pas en UTF-8\n",
    "kickstarter_2016 = pd.read_csv(\"/Users/jl/Downloads/ks-projects-201612.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquez que nous obtenons la même UnicodeDecodeError que lorsque nous avons essayé de décoder des octets UTF-8 comme s'il s'agissait d'ASCII ! Cela nous indique que ce fichier n'est pas réellement UTF-8. Nous ne savons pas quel est l'encodage réel. Une façon de le découvrir est d'essayer et de tester un tas d'encodages de caractères différents et de voir si l'un d'entre eux fonctionne. Une meilleure façon, cependant, est d'utiliser le module chardet pour essayer de deviner automatiquement quel est le bon encodage. Ce n'est pas garanti à 100%, mais c'est généralement plus rapide que d'essayer de deviner.\n",
    "\n",
    "Je vais me contenter de regarder les dix mille premiers octets de ce fichier. C'est généralement suffisant pour avoir une bonne idée de l'encodage et c'est beaucoup plus rapide que d'essayer de regarder l'ensemble du fichier. (Une autre raison de ne regarder que la première partie du fichier est que nous pouvons voir, en regardant le message d'erreur, que le premier problème est le 11ème caractère. Nous n'avons donc probablement besoin que de la première partie du fichier pour comprendre ce qui se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "# regarder les dix mille premiers octets pour deviner l'encodage des caractères\n",
    "with open(\"/Users/jl/Downloads/ks-projects-201801.csv\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "\n",
    "# vérifie l'encodage des caractères\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc chardet est sûr à 73% que le bon encodage est \"Windows-1252\". Voyons si c'est correct :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r5/sycktgpj0ln8vbwphhbh5mb00000gn/T/ipykernel_34170/13219038.py:2: DtypeWarning: Columns (13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  kickstarter_2016 = pd.read_csv(\"/Users/jl/Downloads/ks-projects-201612.csv\", encoding='Windows-1252')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09 11:36:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26 00:20:50</td>\n",
       "      <td>45000</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16 04:24:11</td>\n",
       "      <td>5000</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29 01:00:00</td>\n",
       "      <td>19500</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000014025</td>\n",
       "      <td>Monarch Espresso Bar</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-04-01 13:38:27</td>\n",
       "      <td>50000</td>\n",
       "      <td>2016-02-26 13:38:27</td>\n",
       "      <td>52375</td>\n",
       "      <td>successful</td>\n",
       "      <td>224</td>\n",
       "      <td>US</td>\n",
       "      <td>52375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               name   \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000004038                                     Where is Hank?   \n",
       "2  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "3  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "4  1000014025                               Monarch Espresso Bar   \n",
       "\n",
       "        category  main_category  currency             deadline   goal   \\\n",
       "0          Poetry     Publishing       GBP  2015-10-09 11:36:00   1000   \n",
       "1  Narrative Film   Film & Video       USD  2013-02-26 00:20:50  45000   \n",
       "2           Music          Music       USD  2012-04-16 04:24:11   5000   \n",
       "3    Film & Video   Film & Video       USD  2015-08-29 01:00:00  19500   \n",
       "4     Restaurants           Food       USD  2016-04-01 13:38:27  50000   \n",
       "\n",
       "             launched  pledged       state  backers  country  usd pledged   \\\n",
       "0  2015-08-11 12:12:28        0      failed        0       GB            0   \n",
       "1  2013-01-12 00:20:50      220      failed        3       US          220   \n",
       "2  2012-03-17 03:24:11        1      failed        1       US            1   \n",
       "3  2015-07-04 08:35:03     1283    canceled       14       US         1283   \n",
       "4  2016-02-26 13:38:27    52375  successful      224       US        52375   \n",
       "\n",
       "  Unnamed: 13 Unnamed: 14 Unnamed: 15  Unnamed: 16  \n",
       "0         NaN         NaN         NaN          NaN  \n",
       "1         NaN         NaN         NaN          NaN  \n",
       "2         NaN         NaN         NaN          NaN  \n",
       "3         NaN         NaN         NaN          NaN  \n",
       "4         NaN         NaN         NaN          NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lire le fichier avec l'encodage détecté par chardet\n",
    "kickstarter_2016 = pd.read_csv(\"/Users/jl/Downloads/ks-projects-201612.csv\", encoding='Windows-1252')\n",
    "\n",
    "# regarder les premières lignes\n",
    "kickstarter_2016.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui, on dirait que Chardet avait raison ! Le fichier se lit sans problème (bien que nous ayons un avertissement sur les types de données) et lorsque nous regardons les premières lignes, tout semble aller bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enregistrer vos fichiers avec le codage UTF-8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, une fois que vous vous êtes donné la peine de convertir votre fichier en UTF-8, vous voudrez probablement le conserver. La façon la plus simple de le faire est d'enregistrer vos fichiers avec l'encodage UTF-8. La bonne nouvelle est que, puisque l'UTF-8 est l'encodage standard de Python, lorsque vous enregistrez un fichier, il sera enregistré en UTF-8 par défaut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrer notre fichier (il sera enregistré en UTF-8 par défaut !)\n",
    "kickstarter_2016.to_csv(\"/Users/jl/Downloads/ks-projects-201801.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
